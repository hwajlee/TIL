{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a809296",
   "metadata": {},
   "source": [
    "###  Model selection 모듈 소개 \n",
    "사이킷런의 model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공한다. 먼저 앞의 예제에서도 소개했지만, 전체 데이터를 학습 데이터와 테스트 데이터 세트로 분리해주는 train_test_split()부터 자세히 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435e630",
   "metadata": {},
   "source": [
    "#### 학습/테스트 데이터 세트 분리 - train_test_split()\n",
    "먼저 테스트 데이터 세트를 이용하지 않고 학습 데이터 세트로만 학습하고 예측하면 무엇이 문제인지 살펴보겠습니다.\n",
    "다음 예제는 학습과 예측을 동일한 데이터 세트로 수행한 결과이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f392cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이리스 \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 의사결정나무 \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# 평가지표\n",
    "from sklearn.metrics import accuracy_score as acc_sc # alias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b16846",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X_data = iris.data # X = 독립변수 = 설명변수 = feature(머신러닝)\n",
    "y_target = iris.target # y = 종속변수(이산) = target = label \n",
    "\n",
    "## 의사결정나무 객체화\n",
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3727b0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_data.copy()\n",
    "y_train = y_target.copy()\n",
    "\n",
    "### 학습을 수행\n",
    "dt_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432fbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 예측을 수행 \n",
    "y_pred = dt_clf.predict(X_train) #<- 2차원의 입력 X가 들어와야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d9cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:1.0\n"
     ]
    }
   ],
   "source": [
    "# 평가지표로 평가 - acc_sc\n",
    "print(f'예측 정확도:{acc_sc(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff964b",
   "metadata": {},
   "source": [
    "위의 예측 결과가 100% 정확한 이유는 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문이다. 즉, 모의고사를 이미 한 번 보고 답을 알고 있는 상태에서 모의고사 문제와 똑같은 본고사 문제가 출제됐기 때문이다. 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야 한다. 사이킷런의 train_test_split()를 통해 원본 데이터 세트에서 학습 및 테스트 데이터 세트를 쉽게 분리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b0481",
   "metadata": {},
   "source": [
    "sklearn.model_selection 모듈에서 train_test_split를 로드해본다. train_test_split()는 첫 번째 파라미터로 피처 데이터 세트, 두 번째 파라미터로 레이블 데이터 세트를 입력받는다. 그리고 선택적으로 다음 파라미터를 입력받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d04bee",
   "metadata": {},
   "source": [
    "* test_size: 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정한다. Default는 0.25, 즉 25%이다. \n",
    "\n",
    "\n",
    "* train_size: 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정한다. test_size parameter를 통상적으로 사용하기 때문에 train_size는 잘 사용되지는 않는다.\n",
    "\n",
    "\n",
    "* shuffle: 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정한다. Default는 True이다. 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는데 사용된다.\n",
    "\n",
    "\n",
    "* random_state: random_state는 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값이다. train_test_split()는 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터를 생성한다. 이 책에서 소개하는 예제는 실습용 예제이므로 수행할 때마다 동일한 데이터 세트로 분리하기 위해 random_state를 일정한 숫자 값으로 부여하겠다.\n",
    "\n",
    "\n",
    "* train_test_split()의 반환값은 튜플 형태이다. 순차적으로 학습용 데이터의 피처 데이터 세트, 테스트용 데이터의 피처 데이터 세트, 학습용 데이터의 레이블 데이터 세트, 테스트용 데이터의 레이블 데이터 세트가 반환된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c1039",
   "metadata": {},
   "source": [
    "붓꽃 데이터 세트를 train_test_split()을 이용해 테스트 데이터 세트를 전체의 30%로, 학습데이터 세트를 70%로 분리해보자. 앞의 예제와는 다르게 random_state=121로 변경해 데이터 세트를 변화시켜 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4790ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train과 test 두 가지를 분리하는 것 :: Hold_out(홀드아웃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e89eb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_1 = np.arange(1, 10)\n",
    "array_11 = np.arange(11, 20)\n",
    "\n",
    "train1, test1, train11, test11 = train_test_split(array_1, array_11, test_size = 0.2, random_state=121) # train >= 50% :: 한국갬성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5763f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 2, 5, 1, 6, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af765679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "403d461c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 17, 12, 15, 11, 16, 13])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42806a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 19])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98b03966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y를 분할해보자\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb151815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 재학습 \n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "## 예측수행\n",
    "y_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "756fb6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측정확도f: 0.967\n",
      "예측정확도: 0.967\n"
     ]
    }
   ],
   "source": [
    "## 평가지표\n",
    "\n",
    "print(f'예측정확도f: {np.round(acc_sc(y_test, y_pred),3)}')\n",
    "print('예측정확도: {0:.3f}'.format(acc_sc(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421a28c",
   "metadata": {},
   "source": [
    "테스트 데이터로 예측을 수행한 결과 정확도가 약 95.66%이다. 붓꽃 데이터는 150개의 데이터로 데이터 양이 크지 않아 전체의 30%정도인 테스트 데이터는 45개 정도밖에 되지 않으므로 이를 통해 알고리즘의 예측 성능을 판단하기에는 그리 적절하지 않다. 학습을 위한 데이터의 양을 일정 수준 이상으로 보장하는 것도 중요하나, 학습된 모델에 대해 다양한 데이터를 기반으로 예측성능을 평가해보는 것도 중요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98909b56",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    "\n",
    "앞서 알고리즘을 학습시키는 학습데이터와 이에 대한 예측 성능을 평가하기 위한 별도의 테스트용 데이터가 필요하다고 하였다. 하지만 이 방법 역시 과적합(overfitting)에 취약한 약점을 가질 수 있다.\n",
    "\n",
    "\n",
    "* 과적합이란 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 말한다. \n",
    "\n",
    "\n",
    "그런데 고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향이 생기게 된다. 이러한 문제점을 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420956ab",
   "metadata": {},
   "source": [
    "교차 검증을 좀 더 간략히 설명하자면 본고사를 치르기 전에 모의고사를 여러 번 보는 것이다. 즉, 본 고사가 테스트 데이터 세트에 대해 평가하는 거라면 모의고사는 교차 검증에서 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행하는 것이다. ML은 데이터에 기반한다. 그리고 데이터는 이상치, 분포도, 다양한 속성값, 피처 중요도 등 여러 가지 ML에 영향을 미치는 요소를 가지고 있다. 특정 ML알고리즘에서 최적으로 동작할 수 있도록 데이터를 선별해 학습한다면 실제 데이터 양식과는 많은 차이가 있을 것이고 결국 성능 저하로 이어질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60daf4a2",
   "metadata": {},
   "source": [
    " * 교차 검증은 이러한 데이터 편중을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다.\n",
    " \n",
    "그리고 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라마터 튜닝 등의 모델 최적화를 더욱 손쉽게 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcc9ee",
   "metadata": {},
   "source": [
    "대부분의 ML 모델의 성능 평가는 교차 검증 기반으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스이다. ML에 사용되는 데이터 세트를 세분화해서 학습, 검증, 테스트 데이터 세트로 나눌 수 있다. 테스트 데이터 세트 외에 별도의 검증 데이터 세트를 두어서 최종 평가 이전에 학습된 모델을 다양하게 평가하는데 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfad7d8",
   "metadata": {},
   "source": [
    "#### K 폴드 교차 검증 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a62c00",
   "metadata": {},
   "source": [
    "K 폴드 교차 검증은 가장 보편적인 교차 검증 기법이다. 먼저 K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37112e6",
   "metadata": {},
   "source": [
    "사이킷런에서는 K fold 교차 검증 프로세스를 구현하기 위해 KFold와 StratifiedKFold 클래스를 제공한다. 먼저 Kfold 클래스를 이용해 붓꽃 데이터 세트를 교차 검증하고 예측 정확도를 알아보자. 붓꽃 데이터 세트와 DecisionTreeClassifier를 다시 생성한다. 그리고 5개의 폴드 세트로 분리하는 KFold 객체를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5348d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 호출 \n",
    "# 데이터 관련 함수 \n",
    "# 모델 셀렉션(model selection) 관련 - train_test_split\n",
    "# 필요 알고리즘 호출 -> 의사결정나무, 랜덤포레스트, SVM, ANN.. 등등등 \n",
    "# 평가지표 \n",
    "# 넘파이 // 판다스 \n",
    "\n",
    "\n",
    "# 데이터\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 모델 분할\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 평가지표\n",
    "from sklearn.metrics import accuracy_score as acc_sc \n",
    "\n",
    "# 넘파이 판다스 \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e56269d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 셋의 크기: 150\n"
     ]
    }
   ],
   "source": [
    "# 데이터 재정의\n",
    "iris = load_iris()\n",
    "features = iris.data # X값 \n",
    "label = iris.target # y값\n",
    "\n",
    "# 알고리즘 객체화\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# kfold에서 k=5 로 놓자 \n",
    "kfold = KFold(n_splits=5)\n",
    "print('데이터 셋의 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee301b",
   "metadata": {},
   "source": [
    "KFold(n_splits = 5)로 KFold 객체를 생성했으니 이제 생성된 KFold 객체의 split()을 호출해 전체 붓꽃 데이터를 5개의 폴드 데이터 세트로 분리한다. 전체 붓꽃 데이터는 모두 150개이다. 따라서 학습용 데이터 세트는 이 중 4/5인 120개, 검증 테스트 데이터 세트는 1/5인 30개로 분할된다. \n",
    "\n",
    "다음 예제는 5개의 폴드 세트를 생성하는 KFold 객체의 split()을 호출해 교차 검증 수행 시마다 학습과 검증을 반복해 예측 정확도를 측정한다. 그리고 split()이 어떤 값을 실제로 반환하는지도 확인해보기 위해 검증 데이터 세트의 인덱스도 추출해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfb23ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kfold.split(features):\n",
    "    print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8cd4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "11\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "for i,j in [(1, 2), (11, 22)]:\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46552723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92059cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 3. , 1.4, 0.2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f179a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #1 CV 정확도: 1.0, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#1 검증 데이터셋 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      " #2 CV 정확도: 0.967, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#2 검증 데이터셋 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      " #3 CV 정확도: 0.867, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#3 검증 데이터셋 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      " #4 CV 정확도: 0.933, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#4 검증 데이터셋 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      " #5 CV 정확도: 0.733, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#5 검증 데이터셋 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 평균 CV 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "for train_index, val_index in kfold.split(label):\n",
    "    # Kfold.split()으로 반환된 인덱스를 통해 학습용, 검증용 데이터 정의\n",
    "    X_val, X_train = features[val_index], features[train_index]\n",
    "    y_val, y_train = label[val_index], label[train_index]\n",
    "    \n",
    "    # 각 CV별 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train) # 학습\n",
    "    pred = dt_clf.predict(X_val) # 예측\n",
    "    \n",
    "    # 정확도 지표 계산\n",
    "    accuracy = np.round(acc_sc(y_val, pred), 3)\n",
    "    train_size = X_train.shape[0]\n",
    "    val_size = X_val.shape[0]\n",
    "    n_iter += 1\n",
    "    print(f'\\n #{n_iter} CV 정확도: {accuracy}, 학습데이터 크기: {train_size}, 검증데이터 크기: {val_size}')\n",
    "    print(f'#{n_iter} 검증 데이터셋 인덱스:{val_index}')\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 개별 iteration 별 정확도 평균내기 \n",
    "print(f'\\n ## 평균 CV 정확도: {np.mean(cv_accuracy)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f769b8",
   "metadata": {},
   "source": [
    "5차 교차 검증 결과 평균 검증 정확도는 0.9이다. 그리고 교차 검증 시마다 검증 세트의 인덱스가 달라짐을 알 수 있다. 학습 데이터 세트의 인덱스는 수가 많아서 출력하지 않았디만 검증 세트의 인덱스를 보면 교차 검증 시마다 split()함수가 어떻게 인덱스를 할당하는지 알 수 있다. 첫 번째 교차 검증에서는 0번-29번까지, 두 번째는 30번-59번, 세 번째는 60번-59번, 네 번째는 90-119번, 다섯 번째는 120-149번으로 각각 30개의 검증 세트 인덱스를 생성했고, 이를 기반으로 검증세트를 추출하게 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
